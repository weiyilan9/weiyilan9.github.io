
## Research Development Trajectory

My research journey demonstrates a natural progression from voice technology to neuroscience. Beginning with my master's research in speech synthesis, I developed a keen interest in how intonation variations in language affect semantics. After entering my doctoral studies, I first explored children's speech database construction at the PedzSTAR Lab, then applied machine learning techniques to speech disorder classification at the SoundBrain Lab. These experiences not only deepened my understanding of speech processing but also cultivated my expertise in machine learning. Currently at the Contreras Lab, I have successfully transferred these skills to the field of neuroscience, using machine learning techniques to analyze animal behavior for studying the effects of hypoxia on the nervous system. This research trajectory reflects how I have combined my expertise in voice technology with computational methods to explore broader questions in neuroscience and behavioral research.


## Neuroscience and Behavioral Research

**Contreras Lab, Northwestern University** | 2025-Present

**Principal Investigator**: Adrian Rodriguez-Contreras

**Project**: Using Animal Models to Study Neurological Changes in Neonates Due to Hypoxia

At the Contreras Lab, I am investigating the neurological impacts of hypoxia on newborn rats, providing valuable insights into potential neurodevelopmental issues faced by human neonates experiencing oxygen deprivation. My work involves monitoring weight changes, spatial decision-making abilities, and sleep pattern adjustments in rat pups under hypoxic conditions. To precisely quantify these behavioral changes, I apply machine learning models like DeepLabCut to automatically capture and analyze animal behavioral trajectories, an application that stems from my previous machine learning experience in voice technology. This research experience has not only broadened my understanding of neuroscience but also familiarized me with the complete workflow of animal experimentation while successfully extending my machine learning skills to computer vision and automated behavioral analysis.


## Speech Processing and Machine Learning

**SoundBrain Lab, Northwestern University** | 2025

**Principal Investigator**: Bharath Chandrasekaran

**Project**: Automatic Phoneme Prediction, Using Machine Learning Methods to Build Classifier of Children Speech Disorders

At the SoundBrain Lab, I focused on developing automatic phoneme prediction systems, a natural continuation of my interest in speech synthesis from my master's research. I utilized open-source models to automatically predict phonemes and compared them with manually transcribed ones to assess prediction accuracy. Building on this, I applied various machine learning techniques including Support Vector Machines, Random Forests, and Deep Neural Networks to classify speech disorders in children. I also explored the role of acoustic features in speech intelligibility and discrimination disorders, work that has intrinsic connections to my master's thesis research on how sentence stress placement affects semantics. This experience significantly strengthened my expertise in speech processing, machine learning for speech signals, and high-performance computing using the QUEST cluster, while also laying the groundwork for my later application of machine learning techniques to analyze animal behavior at the Contreras Lab.


## Pediatric Speech Technology Research

**PedzSTAR Lab, Northwestern University** | 2024

**Principal Investigator**: Marisha Speights

**Project**: Building Audio Databases for Technology Equity

At the Pediatric Speech Technologies and Acoustics Research Lab, I contributed to the construction of a children's speech database, my first doctoral research project and the starting point of my transition from speech synthesis to speech analysis. I assisted in developing audio quality assessment criteria and performed audio auditing while attempting audio noise reduction. I also collected literature on machine learning applications in children's speech disorders, which laid the theoretical foundation for my later development of children's speech disorder classifiers at the SoundBrain Lab. This experience deepened my understanding of audio data processing, quality assessment, and noise reduction techniques, while also making me aware of the significant potential of speech technology in clinical applications, ultimately guiding me to expand my research interests to the broader fields of neuroscience and behavioral research.
